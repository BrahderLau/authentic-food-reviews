{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all the necessary python libraries if anaconda is not able to find them.\n",
    "\n",
    "# WEBSITE JAKIM HALAL CACATTTTTTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary python libraries\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CONSTANTS\n",
    "BASE_URL = 'https://www.verifyhalal.com/Directory/PremiseDetails?premiseID='\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Variables\n",
    "prod_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\n",
    "       BASE_URL + \"190141\"\n",
    ")\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTFU RESTAURANTS SDN. BHD.\n",
      "BANANABRO - KOTA DAMANSARA\n"
     ]
    }
   ],
   "source": [
    "# Find Product Brand & Product Name\n",
    "\n",
    "prod_brand_element = soup.find('span', class_='prodBrand')\n",
    "prod_name_element = soup.find('h1', class_='prodName')\n",
    "\n",
    "if prod_brand_element:\n",
    "    print(prod_brand_element.text)\n",
    "    print(prod_name_element.text)\n",
    "else:\n",
    "    print(\"Element not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25-1 JALAN PJU 5/9 DATARAN SUNWAY KOTA DAMANSARA, PETALING JAYA\n"
     ]
    }
   ],
   "source": [
    "# Find Address\n",
    "address_h4 = soup.find('h4', string=\"Address\")\n",
    "\n",
    "if address_h4:\n",
    "    address = address_h4.find_next_sibling('p')\n",
    "    if address:\n",
    "        address = address.text.strip() \n",
    "        print(address)\n",
    "    else:\n",
    "        print(\"Value of address not found.\")\n",
    "else:\n",
    "    print(\"Address not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-15\n"
     ]
    }
   ],
   "source": [
    "# Find Expiry Date\n",
    "expiry_date_h4 = soup.find('h4', string='Expiry Date')\n",
    "if expiry_date_h4:\n",
    "    next_td_expiry_date = expiry_date_h4.find_parent('td').find_next_sibling('td')\n",
    "    if next_td_expiry_date:\n",
    "        expiry_date = next_td_expiry_date.text.strip()\n",
    "        print(expiry_date)\n",
    "    else:\n",
    "        print(\"Value of expiry date not found.\")\n",
    "else:\n",
    "    print(\"Expiry Date not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jabatan Kemajuan Islam Malaysia (JAKIM)\n"
     ]
    }
   ],
   "source": [
    "# Find Certificate Body\n",
    "certification_body_h4 = soup.find('h4', string='Certification Body')\n",
    "if certification_body_h4:\n",
    "    next_tr_certification_body = certification_body_h4.find_parent('tr').find_next_sibling('tr')\n",
    "    if next_tr_certification_body:\n",
    "        certification_body = next_tr_certification_body.text.strip()\n",
    "        print(certification_body)\n",
    "    else:\n",
    "        print(\"Value of certification body not found.\")\n",
    "else:\n",
    "    print(\"Certification Body not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_and_save_details(response_text, premise_id):\n",
    "    soup = BeautifulSoup(response_text, 'html.parser')\n",
    "    prod_brand = ''\n",
    "    prod_name = ''\n",
    "    prod_address = '' \n",
    "    prod_halal_cert_date = '' \n",
    "    prod_halal_cert_body = ''\n",
    "\n",
    "    # Product Brand\n",
    "\n",
    "    try:\n",
    "        prod_brand_span = soup.find('span', class_='prodBrand')\n",
    "        if prod_brand_element:\n",
    "            prod_brand = prod_brand_span.text\n",
    "        else:\n",
    "            prod_brand = None\n",
    "    except Exception:\n",
    "        prod_brand = None\n",
    "        pass\n",
    "\n",
    "    # Product Name\n",
    "\n",
    "    try:\n",
    "        prod_name_h1 = soup.find('h1', class_='prodName')\n",
    "        if prod_brand_element:\n",
    "            prod_name = prod_name_h1.text\n",
    "        else:\n",
    "            prod_name = None\n",
    "    except Exception:\n",
    "        prod_name = None\n",
    "        pass \n",
    "\n",
    "    # Address\n",
    "\n",
    "    try:\n",
    "        address_h4 = soup.find('h4', string=\"Address\")\n",
    "        if address_h4:\n",
    "            next_p_address = address_h4.find_next_sibling('p')\n",
    "            if next_p_address:\n",
    "                prod_address = next_p_address.text.strip() \n",
    "            else:\n",
    "                prod_address = None\n",
    "        else:\n",
    "            prod_address = None\n",
    "    except Exception:\n",
    "        prod_address = None\n",
    "        pass\n",
    "\n",
    "    # Product Halal Certificate Date\n",
    "\n",
    "    try:\n",
    "        expiry_date_h4 = soup.find('h4', string='Expiry Date')\n",
    "        if expiry_date_h4:\n",
    "            next_td_expiry_date = expiry_date_h4.find_parent('td').find_next_sibling('td')\n",
    "            if next_td_expiry_date:\n",
    "                prod_halal_cert_date = next_td_expiry_date.text.strip() \n",
    "            else:\n",
    "                prod_halal_cert_date = None\n",
    "        else:\n",
    "            prod_halal_cert_date = None\n",
    "    except Exception:\n",
    "        prod_halal_cert_date = None\n",
    "        pass \n",
    "\n",
    "    # Product Halal Certificate Date\n",
    "\n",
    "    try:\n",
    "        certification_body_h4 = soup.find('h4', string='Certification Body')\n",
    "        if expiry_date_h4:\n",
    "            next_tr_certification_body = certification_body_h4.find_parent('tr').find_next_sibling('tr')\n",
    "            if next_tr_certification_body:\n",
    "                prod_halal_cert_body = next_tr_certification_body.text.strip()\n",
    "            else:\n",
    "                prod_halal_cert_body = None\n",
    "        else:\n",
    "            prod_halal_cert_body = None\n",
    "    except Exception:\n",
    "        prod_halal_cert_body = None\n",
    "        pass\n",
    "\n",
    "    prod_details = {\n",
    "        \"Premise Name\": prod_name,\n",
    "        \"Company Brand Name\": prod_brand,\n",
    "        \"Address\": prod_address,\n",
    "        \"Halal Certification Expiry Date\": prod_halal_cert_date,\n",
    "        \"Halal Certification Body\": prod_halal_cert_body\n",
    "    }\n",
    "    #tqdm.write(f'Premise ID: {premise_id}, Data: {prod_details}')\n",
    "    #prod_list.append(prod_details)\n",
    "    #df = pd.DataFrame(prod_details)\n",
    "    #df.append(prod_details, ignore_index=True)\n",
    "    pd.DataFrame([prod_details]).to_csv('premis_makanan_list_part_3.csv',mode='a',index=False,header=False,encoding='utf-8')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for premise_id in tqdm(range(134944, 167473), desc=\"Fetching premises\"):\n",
    "    formatted_premise_id = f\"{premise_id:06}\"\n",
    "    url = f\"{BASE_URL}{formatted_premise_id}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            parse_and_save_details(response.text, formatted_premise_id)\n",
    "        else:\n",
    "            print(f\"Page not found for premiseID={formatted_premise_id}, status code: {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed for premiseID={formatted_premise_id}, error: {e}\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(0.5)  # Sleep for 0.5 second to be polite and not overwhelm the server :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(prod_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('premis_makanan_list_part_3.csv',mode='a',index=False,header=False,encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
